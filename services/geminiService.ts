import { GoogleGenerativeAI } from "@google/generative-ai";
import { AgentConfig } from "../types";

// Helper para obtener el cliente de forma segura
const getClient = () => {
  const apiKey = import.meta.env.VITE_API_KEY;
  
  if (!apiKey) {
    console.error("ðŸ”‘ API Key no encontrada en import.meta.env.VITE_API_KEY");
    throw new Error("API Key no configurada");
  }
  
  console.log("ðŸ”‘ API Key detectada (empieza con):", apiKey.substring(0, 6) + "...");
  return new GoogleGenerativeAI(apiKey);
};

// Crear sesiÃ³n de chat
export const createChatSession = (config: AgentConfig) => {
  try {
    const genAI = getClient();
    console.log("ðŸ¤– Inicializando chat con modelo:", config.model);
    
    const model = genAI.getGenerativeModel({ 
      model: config.model,
      systemInstruction: config.systemInstruction,
    });
    
    const tools = config.useSearch ? [{ googleSearch: {} }] : undefined;
    
    const chat = model.startChat({
      history: [],
      generationConfig: {
        temperature: config.temperature,
        maxOutputTokens: 1000,
      },
      tools: tools,
    });

    console.log("âœ… SesiÃ³n de chat creada exitosamente");
    return chat;
  } catch (error) {
    console.error("âŒ Error al crear la sesiÃ³n de chat:", error);
    throw error;
  }
};

// Enviar mensaje con streaming - VERSIÃ“N CORREGIDA
export async function* streamMessage(chat: any, message: string) {
  try {
    if (!message || !message.trim()) {
      throw new Error("Mensaje vacÃ­o, no se puede enviar a Gemini");
    }

    console.log("ðŸ“¤ Enviando mensaje a Gemini:", message.substring(0, 100) + "...");

    // ðŸ‘‡ FORMATO ABSOLUTAMENTE CORRECTO para Gemini
    // La API espera un objeto con la estructura especÃ­fica
    const result = await chat.sendMessageStream(message);

    console.log("ðŸ“¨ Respuesta recibida, iniciando stream...");

    let receivedChunks = 0;
    
    for await (const chunk of result.stream) {
      receivedChunks++;
      try {
        const chunkText = chunk.text();
        console.log(`ðŸ“¦ Chunk ${receivedChunks}:`, chunkText?.substring(0, 50) + "...");

        yield {
          text: chunkText || "",
          groundingChunks: chunk.groundingMetadata?.groundingChunks || [],
        };
      } catch (chunkError) {
        console.warn("âš ï¸ Error procesando chunk:", chunkError);
        continue;
      }
    }

    console.log(`âœ… Stream completado. Chunks recibidos: ${receivedChunks}`);

  } catch (error: any) {
    console.error("âŒ Error crÃ­tico en stream:", error);
    
    // AnÃ¡lisis detallado del error
    if (error.message?.includes("ContentUnion")) {
      console.error("ðŸ” Problema de formato ContentUnion detectado");
      throw new Error("Error de formato en el mensaje (ContentUnion). La API de Gemini cambiÃ³ recientemente.");
    }
    
    if (error.message?.includes("API key")) {
      throw new Error("Problema con la API Key. Verifica que sea vÃ¡lida y tenga permisos.");
    }
    
    throw new Error(`Error al comunicarse con Gemini: ${error.message}`);
  }
}

// VersiÃ³n alternativa sin streaming (fallback robusto)
export const sendMessageSimple = async (chat: any, message: string) => {
  try {
    console.log("ðŸ”„ Usando mÃ©todo simple para mensaje:", message.substring(0, 100) + "...");
    
    const result = await chat.sendMessage(message);
    const response = await result.response;
    
    console.log("âœ… Respuesta simple recibida");
    return response.text();
  } catch (error: any) {
    console.error("âŒ Error en mÃ©todo simple:", error);
    
    // Intentar con generateContent como Ãºltimo recurso
    try {
      console.log("ðŸ”„ Intentando con generateContent...");
      const genAI = getClient();
      const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });
      const result = await model.generateContent(message);
      return result.response.text();
    } catch (finalError) {
      throw new Error(`No se pudo procesar el mensaje: ${error.message}`);
    }
  }
};

// AnÃ¡lisis de datos financieros
export const analyzeFinancialData = async (data: string) => {
  try {
    const genAI = getClient();
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    
    const prompt = `Analiza los siguientes datos financieros: ${data}`;
    const result = await model.generateContent(prompt);
    
    return result.response.text();
  } catch (error) {
    console.error("Error al analizar datos:", error);
    throw error;
  }
};

export default { 
  createChatSession, 
  streamMessage, 
  sendMessageSimple,
  analyzeFinancialData 
};
